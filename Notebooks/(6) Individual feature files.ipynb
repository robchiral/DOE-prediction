{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac713cc-79c4-4f0a-9083-9e4b319db086",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "import numpy as np\n",
    "\n",
    "###\n",
    "\n",
    "targets = pd.read_pickle('./OT/Final/targets.pkl')\n",
    "\n",
    "# See \"Diseases.ipynb\" for these files\n",
    "custom = pd.read_excel('./Phenotyping/custom_phenotypes.xlsx')\n",
    "custom['phecode1.2'] = custom['phecode1.2'].astype(float)\n",
    "icd = pd.read_csv('./Phenotyping/icd_codes.csv')\n",
    "merged_pheno = pd.read_excel('./Phenotyping/merged_phenotypes.xlsx')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de62ce16-6b9b-4b6d-80ff-463cc8517290",
   "metadata": {},
   "source": [
    "# Gene-level features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7cd7df-600e-4c11-a5b2-b80214ba68e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open Targets target data 2024.09\n",
    "genes = pd.read_pickle('./OT/Raw/targets.pkl')\n",
    "genes = genes.loc[(genes['biotype'] == 'protein_coding')]\n",
    "genes = genes[['approvedSymbol']].set_axis(['gene'],axis=1)\n",
    "genes.to_pickle('./OT/Final/protein_coding_genes.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a58d0d24-ed3c-4a4a-ab02-e895d6630f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3793286/3367484386.py:44: DtypeWarning: Columns (0,1,2,3,6,7,8,9,17,18,19,20,22,23,25,26,29) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  impc = pd.read_csv('./Other/impc_essential_genes_full_dataset.csv')\n"
     ]
    }
   ],
   "source": [
    "genes = pd.read_pickle('./OT/Final/protein_coding_genes.pkl')\n",
    "\n",
    "# https://pharos.nih.gov\n",
    "pharos = pd.read_csv('./Other/pharos.csv')\n",
    "pharos = pharos[['Symbol','Target Development Level','IDG Family','Antibody Count']].set_axis(['gene','tdl','type','mab_count'],axis=1)\n",
    "pharos['tdl'] = pharos['tdl'].fillna('Tdark')\n",
    "pharos['type'] = pharos['type'].fillna('Other')\n",
    "tp = genes.merge(pharos, how='left')\n",
    "\n",
    "# Open Targets target prioritization view 2024.09\n",
    "spec = pd.read_pickle('./OT/Raw/targetPrioritisation.pkl').rename({'targetId':'gene_id'},axis=1).merge(targets)\n",
    "tp = tp.merge(spec[['gene','tissueSpecificity','tissueDistribution',\n",
    "                    'hasLigand','hasSmallMoleculeBinder','hasPocket',\n",
    "                    'mouseKOScore','isCancerDriverGene','paralogMaxIdentityPercentage']], how='left')\n",
    "\n",
    "# https://www.proteinatlas.org/humanproteome/proteinclasses\n",
    "tp.loc[tp['gene'].isin(pd.read_csv('./Other/HPA/protein_location_Intracellular.tsv', sep='\\t')['Gene']),'loc_intracellular'] = 1\n",
    "tp.loc[tp['gene'].isin(pd.read_csv('./Other/HPA/protein_location_Membrane.tsv', sep='\\t')['Gene']),'loc_membrane'] = 1\n",
    "tp.loc[tp['gene'].isin(pd.read_csv('./Other/HPA/protein_location_Secreted.tsv', sep='\\t')['Gene']),'loc_secreted'] = 1\n",
    "tp.loc[tp['gene'].isin(pd.read_csv('./Other/HPA/protein_class_Plasma.tsv', sep='\\t')['Gene']),'loc_plasma'] = 1\n",
    "\n",
    "tp.loc[tp['gene'].isin(pd.read_csv('./Other/HPA/protein_class_Enzymes.tsv', sep='\\t')['Gene']),'class_enzyme'] = 1\n",
    "tp.loc[tp['gene'].isin(pd.read_csv('./Other/HPA/protein_class_Transporters.tsv', sep='\\t')['Gene']),'class_transporter'] = 1\n",
    "tp.loc[tp['gene'].isin(pd.read_csv('./Other/HPA/protein_class_Transcription.tsv', sep='\\t')['Gene']),'class_tf'] = 1\n",
    "tp.loc[tp['gene'].isin(pd.read_csv('./Other/HPA/protein_class_G-protein.tsv', sep='\\t')['Gene']),'class_gpcr'] = 1\n",
    "tp.loc[tp['gene'].isin(pd.read_csv('./Other/HPA/protein_class_Voltage-gated.tsv', sep='\\t')['Gene']),'class_vgic'] = 1\n",
    "\n",
    "tp.loc[tp['type'] == 'Enzyme', 'class_enzyme'] = 1\n",
    "tp.loc[tp['type'] == 'Transcription Factor', 'class_tf'] = 1\n",
    "tp.loc[tp['type'] == 'Transporter', 'class_transporter'] = 1\n",
    "tp.loc[tp['type'] == 'Kinase', 'class_enzyme'] = 1\n",
    "tp.loc[tp['type'] == 'GPCR', 'class_gpcr'] = 1\n",
    "tp.loc[tp['type'] == 'oGPCR', 'class_gpcr'] = 1\n",
    "tp.loc[tp['type'] == 'Ion Channel', 'class_vgic'] = 1\n",
    "tp = tp.drop('type',axis=1)\n",
    "tp.to_pickle('./Features/tp.pkl')\n",
    "\n",
    "# https://gnomad.broadinstitute.org/data#v4-constraint\n",
    "gn = pd.read_csv('./Other/gnomad.v4.1.constraint_metrics.tsv', sep='\\t')\n",
    "gn = gn.loc[gn['canonical'] == True].rename({'gene':'og_gene'},axis=1)\n",
    "gn = gn.merge(targets, how='left')\n",
    "gn['gene'] = gn['gene'].fillna(gn['og_gene'])\n",
    "gn = gn.groupby('gene')[['lof_hc_lc.oe','lof_hc_lc.pLI','lof_hc_lc.pRec','lof_hc_lc.pNull',\n",
    "                         'lof.oe','lof.pLI','lof.pRec','lof.pNull','lof.oe_ci.upper','lof.oe_ci.upper_bin_decile',\n",
    "                         'mis.oe','mis_pphen.oe','syn.oe']].mean().reset_index()\n",
    "for col in ['lof_hc_lc.pLI','lof_hc_lc.pRec','lof_hc_lc.pNull','lof.pLI','lof.pRec','lof.pNull']:\n",
    "    gn[col] = -np.log10(gn[col])\n",
    "    gn[col] = gn[col].replace([np.inf, -np.inf], 325)\n",
    "gn.loc[:, gn.columns != 'gene'] = gn.loc[:, gn.columns != 'gene'].round(4)\n",
    "gn.to_pickle('./Features/constraint.pkl')\n",
    "\n",
    "# https://academic.oup.com/nar/advance-article/doi/10.1093/nar/gkae1079/7907365#494838589\n",
    "gofcards = pd.read_excel('./GoFCards/gofcards_data_download.xlsx')[['genesymbol']].rename({'genesymbol':'gene'},axis=1)\n",
    "gofcards['gofcards'] = 1\n",
    "\n",
    "# https://omim.org/downloads/\n",
    "om = pd.read_csv('./Other/genemap2.txt',sep='\\t', skiprows=3)\n",
    "om = om[['Approved Gene Symbol','Phenotypes']].dropna()\n",
    "om['Phenotypes'] = om['Phenotypes'].str.split(';')\n",
    "om = om.explode('Phenotypes')\n",
    "om = om.loc[om['Phenotypes'].str.contains('(3)', regex=False)]\n",
    "#om['Inheritance'] = om['Phenotypes'].str.split(',').str[-1]\n",
    "om.loc[om['Phenotypes'].str.contains('Autosomal recessive', case=False), 'Inheritance'] = 'AR'\n",
    "om.loc[om['Phenotypes'].str.contains('Autosomal dominant', case=False), 'Inheritance'] = 'AD'\n",
    "om['value'] = 1\n",
    "om = pd.pivot_table(om, index='Approved Gene Symbol', columns='Inheritance', values='value').reset_index()\n",
    "om = om.set_axis(['gene','omim_ad','omim_ar'],axis=1)\n",
    "\n",
    "# https://forum.depmap.org/t/common-essential-gene-list/2576\n",
    "dpm = pd.read_csv('./Other/Gene Dependency Profile Summary.csv')\n",
    "dpm = dpm.loc[dpm['Dataset'] == 'DependencyEnum.Chronos_Combined']\n",
    "dpm = dpm[['Gene','Strongly Selective','Common Essential']]\n",
    "dpm = dpm.set_axis(['gene','depmap_ss','depmap_ce'],axis=1)\n",
    "dpm[['depmap_ss','depmap_ce']] = dpm[['depmap_ss','depmap_ce']].astype(int)\n",
    "\n",
    "# https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0307312\n",
    "# https://osf.io/z4dcp/?view_only=\n",
    "gld = pd.read_csv('./Other/pgof_svm_poly_2023-07-25.tsv', sep='\\t')[['gene','pGOF']]\n",
    "gld = gld.merge(pd.read_csv('./Other/pdn_svm_poly_2023-07-25.tsv', sep='\\t')[['gene','pDN']], how='outer')\n",
    "gld = gld.merge(pd.read_csv('./Other/plof_svm_poly_2023-07-28.tsv', sep='\\t')[['gene','pLOF']], how='outer')\n",
    "gld = gld.set_axis(['gene','badonyi_pgof','badonyi_pdn','badonyi_plof'],axis=1)\n",
    "\n",
    "# https://www.sciencedirect.com/science/article/pii/S0092867422007887#sec4.1\n",
    "cs = pd.read_csv('./Other/Collins_rCNV_2022.dosage_sensitivity_scores.tsv', sep='\\t')\n",
    "cs = cs.set_axis(['gene','collins_phaplo','collins_ptriplo'],axis=1)\n",
    "\n",
    "# https://search.clinicalgenome.org/kb/gene-dosage?page=1&size=All&search=\n",
    "cds = pd.read_csv('./Other/clingen_dosage_sensitivity.csv')\n",
    "cds = cds.loc[cds['Type'] == 'Gene']\n",
    "cds['gene'] = cds['Gene Symbol /Region Name'].str.split('HGNC').str[0]\n",
    "cds['clingen_hi'] = cds['HI Score'].map({'AutosomalRecessive':-2,'SensitivityUnlikely':-1,\n",
    "                    'SufficientEvidence':3,'EmergingEvidence':2,'LittleEvidence':1,'NoEvidence':0})\n",
    "cds = cds[['gene','clingen_hi']].dropna().drop_duplicates()\n",
    "\n",
    "# IMPC mouse essentiality\n",
    "impc = pd.read_csv('./Other/impc_essential_genes_full_dataset.csv')\n",
    "impc = impc.loc[impc['orthologue_category'] == 'GOOD']\n",
    "impc = impc[['human_ensembl_gene_acc_id','impc_via_category']].dropna()\n",
    "impc = impc.set_axis(['gene_id','impc_ko'],axis=1).merge(targets)\n",
    "impc['impc_ko'] = impc['impc_ko'].map({'Homozygous-Viable':0,'Homozygous-Lethal':2,'Homozygous-Subviable':1})\n",
    "impc = impc[['gene','impc_ko']].dropna()\n",
    "\n",
    "# Protein length\n",
    "up = pd.read_csv('./Other/uniprot_sequence.csv').rename({'Symbol':'gene'},axis=1)\n",
    "up['protein_length'] = up['Sequence'].str.len()\n",
    "up = up[['gene','protein_length']]\n",
    "\n",
    "# Tau metric\n",
    "gtex = pd.read_csv('./Other/GTEx_Analysis_v10_RNASeQCv2.4.2_gene_median_tpm.gct', skiprows=2, sep='\\t')\n",
    "gtex = gtex.drop('Description',axis=1).rename({'Name':'gene_id'},axis=1)\n",
    "gtex['gene_id'] = gtex['gene_id'].str.split('.').str[0]\n",
    "gtex = gtex.merge(targets).drop('gene_id',axis=1).groupby('gene').mean().reset_index()\n",
    "df_log = np.log2(gtex.iloc[:, 1:] + 1)\n",
    "mx = df_log.max(axis=1)\n",
    "tau_vals = (1 - df_log.div(mx, axis=0)).sum(axis=1) / (df_log.shape[1] - 1)\n",
    "gtex['gtex_tau'] = tau_vals\n",
    "gtex = gtex[['gene','gtex_tau']]\n",
    "\n",
    "# Pocket prediction\n",
    "fscore = pd.read_pickle('./Features/fscore.pkl').fillna(0)\n",
    "\n",
    "# OncoKB update 2024-12-19\n",
    "cg = pd.read_csv('./Other/cancerGeneList.tsv', sep='\\t')[['Hugo Symbol','Is Oncogene','Is Tumor Suppressor Gene','# of occurrence within resources (Column J-P)']]\n",
    "cg = cg.set_axis(['gene','oncokb_oncogene','oncokb_suppressor','oncokb_sources'],axis=1)\n",
    "cg['oncokb_oncogene'] = cg['oncokb_oncogene'].map({'Yes':1})\n",
    "cg['oncokb_suppressor'] = cg['oncokb_suppressor'].map({'Yes':1})\n",
    "\n",
    "ess = gofcards.merge(om, how='outer').merge(dpm, how='outer').merge(gld, how='outer')\\\n",
    "        .merge(cs, how='outer').merge(cds, how='outer').merge(impc, how='outer').merge(up, how='outer')\\\n",
    "        .merge(gtex, how='outer').merge(fscore, how='outer').merge(cg, how='outer')\n",
    "ess = ess.groupby('gene').max().reset_index()\n",
    "ess.to_pickle('./Features/ess_haplo.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398e7e1f-cc15-45b9-af89-ecf6f3af80d8",
   "metadata": {},
   "source": [
    "# Gene-disease-specific features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5701cb-ffe9-4e2b-84b0-fbb7e4548c73",
   "metadata": {},
   "source": [
    "## Genebass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fa362d28-f663-4279-a349-54ae46894cc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3248484/4076189414.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  b['Code'] = b['description'].str[5:8]\n",
      "/tmp/ipykernel_3248484/4076189414.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  c['Code'] = c['phenocode'].copy()\n"
     ]
    }
   ],
   "source": [
    "# Identify present phenotypes\n",
    "gbp = pd.read_excel('./Genebass/pheno_results.xlsx')\n",
    "gbp = gbp[['trait_type','phenocode','description','description_more','coding_description']]\n",
    "\n",
    "a = custom[['phenocode','custom_code']].drop_duplicates().dropna().rename({'custom_code':'Code'},axis=1)\n",
    "\n",
    "b = gbp.loc[gbp['trait_type'] == 'icd_first_occurrence']\n",
    "b['Code'] = b['description'].str[5:8]\n",
    "b = b.loc[b['Code'].isin(merged_pheno['Code'])][['phenocode','Code']]\n",
    "\n",
    "c = gbp.loc[gbp['trait_type'] == 'icd10']\n",
    "c['Code'] = c['phenocode'].copy()\n",
    "c = c.loc[c['Code'].isin(merged_pheno['Code'])][['phenocode','Code']]\n",
    "\n",
    "gbp = pd.concat([a,b,c]).drop_duplicates()\n",
    "\n",
    "d = gbp[['Code']].drop_duplicates()\n",
    "d['Genebass'] = 1\n",
    "d.to_csv('./Phenotyping/genebass_present.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd05545-83a1-4953-83c6-7cc9516d3aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create gene burden features\n",
    "gb = pd.read_csv('./Genebass/GB/gb.tsv', sep='\\t')\n",
    "gb = gb.merge(gbp).merge(targets)\n",
    "gb = gb[['Code','gene','annotation','Pvalue_Burden','BETA_Burden']]\n",
    "gb['Pvalue_Burden'] = -np.log10(gb['Pvalue_Burden'])\n",
    "gb = gb.sort_values('Pvalue_Burden', ascending=False).drop_duplicates(['Code','gene','annotation'])\n",
    "gb.loc[gb['BETA_Burden'] < 0, 'Pvalue_Burden'] = gb['Pvalue_Burden']*-1\n",
    "gb = pd.pivot_table(gb, index=['Code','gene'], columns='annotation', values='Pvalue_Burden').reset_index()\n",
    "gb = gb.set_axis(['Code','gene','genebass_gb_hclof_missense','genebass_gb_hclof','genebass_gb_hclof_lclof_missense'],axis=1)\n",
    "gb.to_pickle('./Features/genebass_gb.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa711e9-f328-4154-be8e-9b68365da21a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/sc/arion/projects/GENECAD/Robert/conda/envs/test/lib/python3.12/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: divide by zero encountered in log10\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Create single variant features\n",
    "gb = pd.read_csv('./Genebass/GB/gb.tsv', sep='\\t')\n",
    "gb = gb[['gene_symbol','gene_id']].merge(targets).drop_duplicates()\n",
    "sv = pd.read_pickle('./Genebass/SV/sv.pkl').rename({'gene':'gene_symbol'},axis=1)\n",
    "sv = sv.merge(gbp).drop('phenocode',axis=1)\n",
    "sv = sv.loc[sv['AC'] >= 10]\n",
    "sv['Pvalue'] = -np.log10(sv['Pvalue'])\n",
    "sv = sv.merge(gb, how='left')\n",
    "sv.loc[sv['gene'].isna(), 'gene'] = sv['gene_symbol']\n",
    "sv = sv.drop(['gene_symbol','gene_id','AF'],axis=1)\n",
    "sv = sv.sort_values('Pvalue', ascending=False).drop_duplicates(['markerID','Code'])\n",
    "sv.to_pickle('./Genebass/SV/sv_cleaned.pkl')\n",
    "\n",
    "vep = pd.read_pickle('./Genebass/SV/vep_cleaned.pkl')\n",
    "vep = vep[['ID','SYMBOL','annotation','hc_gof']]\n",
    "\n",
    "sv = pd.read_pickle('./Genebass/SV/sv_cleaned.pkl')\n",
    "sv = sv.rename({'markerID':'ID'},axis=1)\n",
    "sv = sv.drop(['annotation','SE'],axis=1)\n",
    "sv.loc[sv['Pvalue'] > 1000, 'Pvalue'] = sv.loc[sv['Pvalue'] < 1000]['Pvalue'].max()\n",
    "sv = sv.merge(vep)\n",
    "sv = sv.drop('gene',axis=1).rename({'SYMBOL':'gene'},axis=1)\n",
    "sv = sv.sort_values('Pvalue',ascending=False)\n",
    "\n",
    "gof = sv.loc[sv['hc_gof'].notna()].drop_duplicates(['gene','Code'])\n",
    "gof.loc[gof['BETA'] < 0, 'Pvalue'] = gof['Pvalue']*-1\n",
    "gof = gof[['Code','gene','Pvalue']].rename({'Pvalue':'genebass_sv_hcgof'},axis=1)\n",
    "\n",
    "sv = sv.drop_duplicates(['gene','annotation','Code'])\n",
    "sv.loc[sv['BETA'] < 0, 'Pvalue'] = sv['Pvalue']*-1\n",
    "sv = pd.pivot_table(sv, index=['Code','gene'], columns='annotation', values='Pvalue').reset_index()\n",
    "sv = sv.set_axis(['Code','gene','genebass_sv_hclof','genebass_sv_lclof',\n",
    "                               'genebass_sv_lof_0.5missense','genebass_sv_lof_missense',\n",
    "                               'genebass_sv_gof_0.5missense','genebass_sv_gof_missense',\n",
    "                               'genebass_sv_other_0.5missense','genebass_sv_other_missense'],axis=1)\n",
    "sv = sv.merge(gof, on=['Code','gene'], how='outer')\n",
    "sv = sv.dropna(thresh=3, axis=0)\n",
    "sv.to_pickle('./Features/genebass_sv.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8970fd10-b081-4b3b-a429-fb93a8441d0f",
   "metadata": {},
   "source": [
    "## MVP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "bf07b78e-3191-403e-b93e-4537822ab999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify present phenotypes\n",
    "mp = pd.read_excel('./MVP/mvp_phenotypes.xlsx')\n",
    "mp = mp.loc[mp['Category'] == 'PheCodes']\n",
    "mp['pheno'] = mp['Trait'].str.replace('Phe_','').str.replace('_','.')\n",
    "mp['pheno'] = pd.to_numeric(mp['pheno'], errors='coerce')\n",
    "mp = mp[['pheno']].dropna()\n",
    "mp = pcc.merge(mp)[['Code']].drop_duplicates()\n",
    "mp['MVP'] = 1\n",
    "mp.to_csv('./Phenotyping/mvp_present.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47bdfa63-4526-4dcb-a435-f83868e0943d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create eQTL features\n",
    "pcc = pd.read_excel('./Phenotyping/phecode_to_code.xlsx').rename({'phecode1.2':'pheno'},axis=1)\n",
    "df = pd.read_csv('./MVP/combined_eqtl_closest.tsv', sep='\\t')\n",
    "df['pheno'] = df['pheno'].str.replace('Phe_','')\n",
    "df['pheno'] = df['pheno'].str.replace('_','.').astype(float)\n",
    "df = df.merge(pcc)\n",
    "df = df.groupby(['Code','gene'])[['opposite','same']].max().reset_index()\n",
    "df = df.set_axis(['Code','gene','mvp_eqtl_closest_opposite','mvp_eqtl_closest_same'],axis=1)\n",
    "df.to_pickle('./Features/mvp_eqtl_closest.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98901483-5140-4d7c-9353-62784bab84ed",
   "metadata": {},
   "source": [
    "## PanUKBB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c359e91b-81ab-4e4f-921a-8ebce21323cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify present phenotypes\n",
    "pu = pd.read_excel('./PanUKBB/panukbb_pheno.xlsx', usecols = ['trait_type','phenocode','description','aws_link'])\n",
    "pu_icd = pu.loc[(pu['trait_type'] == 'icd10') & (pu['phenocode'].isin(merged_pheno['Code']))]\n",
    "pu_icd['Code'] = pu_icd['phenocode'].copy()\n",
    "pu_icd['pheno'] = pu_icd['trait_type'] + '-' + pu_icd['phenocode']\n",
    "pu_icd = pu_icd[['pheno','Code']]\n",
    "pu_p12 = pu.loc[pu['trait_type'] == 'phecode']\n",
    "pcc = pd.read_excel('./Phenotyping/phecode_to_code.xlsx')\n",
    "pu_p12['phecode1.2'] = pu_p12['phenocode'].astype(float)\n",
    "pu_p12 = pu_p12.merge(pcc)\n",
    "pu_p12['pheno'] = pu_p12['trait_type'] + '-' + pu_p12['phenocode'].astype(str)\n",
    "pu_p12 = pu_p12[['pheno','Code']]\n",
    "pu = pd.concat([pu_icd,pu_p12]).drop_duplicates()\n",
    "\n",
    "d = pu[['Code']].drop_duplicates()\n",
    "d['PanUKBB'] = 1\n",
    "d.to_csv('./Phenotyping/panukbb_present.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376f0e4a-10f4-47fb-9ba4-a5c7245418ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create eQTL features\n",
    "df = pd.read_csv('./PanUKBB/combined_eqtl_closest.tsv', sep='\\t')\n",
    "df = df.merge(pu)\n",
    "df = df.groupby(['Code','gene'])[['opposite','same']].max().reset_index()\n",
    "df = df.set_axis(['Code','gene','panukbb_eqtl_closest_opposite','panukbb_eqtl_closest_same'],axis=1)\n",
    "df.to_pickle('./Features/panukbb_eqtl_closest.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f276fc8-499e-4a87-8cb4-e29eb3de5d71",
   "metadata": {},
   "source": [
    "## Jurgens et al. rare variant analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5f95cb3a-4ea4-4239-a842-6c7349b66353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify present phenotypes\n",
    "results = pd.read_pickle('./Jurgens/UKB_AoU_MGB_combined.pkl')\n",
    "pcc = pd.read_excel('./Phenotyping/phecode_to_code.xlsx')\n",
    "jp = pd.read_excel('./Jurgens/Jurgens.xlsx').rename({'PheCode':'phecode1.2'},axis=1)\n",
    "jp['phecode1.2'] = jp['phecode1.2'].astype(float)\n",
    "jp = jp.merge(pcc)[['Meaning','Code']].set_axis(['phenotype','Code'],axis=1).drop_duplicates()\n",
    "\n",
    "d = jp[['Code']].drop_duplicates()\n",
    "d['Jurgens'] = 1\n",
    "d.to_csv('./Phenotyping/jurgens_present.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b9326104-d499-498b-888c-c71de53e82e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create gene burden features\n",
    "results = results.merge(jp)\n",
    "results = results.drop('phenotype',axis=1)\n",
    "results['mask'] = results['mask'].map({'lof_ms0.5_af0.01':'jurgens_lof_0.5missense',\n",
    "                                       'lof_ms0.5_af0.001':'jurgens_lof_0.5missense',\n",
    "                                       'lof_ms0.5_af0.00001':'jurgens_lof_0.5missense',\n",
    "                                       'ms0.2_af0.00001':'jurgens_0.2missense',\n",
    "                                       'lof_ms0.8_af0.01':'jurgens_lof_0.8missense',\n",
    "                                       'lof_ms0.8_af0.001':'jurgens_lof_0.8missense',\n",
    "                                       'lof_af0.01':'jurgens_lof',\n",
    "                                       'lof_af0.001':'jurgens_lof',\n",
    "                                       'ms0.5_af0.00001':'jurgens_0.5missense'})\n",
    "results = results.sort_values('p', ascending=False).drop_duplicates(['gene','Code','mask'])\n",
    "results.loc[results['beta'] < 0, 'p'] = results['p']*-1\n",
    "results = pd.pivot_table(results, index=['gene','Code'], columns='mask', values='p').reset_index()\n",
    "results.to_pickle('./Features/jurgens.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e1ea73-1bc8-43c7-bf70-4ffaa806f51b",
   "metadata": {},
   "source": [
    "## Finngen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4627a645-df23-4e29-8e50-de2435d1a8e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2453329/3086557317.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  c['ICD_3c'] = c['ICD'].str[:3]\n"
     ]
    }
   ],
   "source": [
    "# Identify present phenotypes\n",
    "fgm = pd.read_csv('./Finngen/finngen_R12_manifest.tsv', sep='\\t')\n",
    "fg = pd.read_excel('./Finngen/finngen_R12_endpoints.xlsx')[['LEVEL','NAME','LONGNAME','HD_ICD_10','COD_ICD_10','version','PARENT']]\n",
    "fg = fg.loc[fg['NAME'].isin(fgm['phenocode'])]\n",
    "fg['ICD'] = fg['HD_ICD_10'].str.replace('.','')\n",
    "\n",
    "a = fg.loc[fg['ICD'].isin(merged_pheno['Code'])]\n",
    "a = a[['NAME','ICD']].set_axis(['pheno','Code'],axis=1)\n",
    "\n",
    "b = fg.merge(custom[['finngen','custom_code']].dropna().drop_duplicates().rename({'finngen':'LONGNAME'},axis=1))\n",
    "b = b[['LONGNAME','custom_code']].set_axis(['pheno','Code'],axis=1)\n",
    "\n",
    "c = fg.loc[(~fg['ICD'].isin(merged_pheno['Code'])) & (fg['HD_ICD_10'].notna())]\n",
    "c['ICD_3c'] = c['ICD'].str[:3]\n",
    "c = c.loc[c['ICD_3c'].isin(merged_pheno['Code'])]\n",
    "c_inc = pd.read_excel('./Finngen/bar_pheno.xlsx')\n",
    "c_inc = c_inc.loc[c_inc['Include'] == 'Y']['NAME']\n",
    "c = c.loc[(~c['HD_ICD_10'].str.contains('|', regex=False)) | (c['NAME'].isin(c_inc))]\n",
    "c = c[['NAME','ICD_3c']].set_axis(['pheno','Code'],axis=1)\n",
    "\n",
    "fg = pd.concat([a,b,c]).drop_duplicates()\n",
    "\n",
    "d = fg[['Code']].drop_duplicates()\n",
    "d['FinnGen'] = 1\n",
    "d.to_csv('./Phenotyping/finngen_present.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda56a74-61fd-47ec-8f82-5109d98cfff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create eQTL features\n",
    "te = pd.DataFrame(columns=['Code','gene'])\n",
    "\n",
    "for tissue in ['Adipose_Subcutaneous','Whole_Blood','Lung','Liver','Brain_Cortex',\n",
    "               'Heart_Left_Ventricle','Kidney_Cortex','Muscle_Skeletal','Artery_Tibial','Cells_Cultured_fibroblasts']:\n",
    "    df = pd.read_csv(f'./Finngen/combined_eqtl_{tissue}_closest.tsv', sep='\\t')\n",
    "    df = df.merge(fg)\n",
    "    df = df.groupby(['Code','gene'])[['opposite','same']].max().reset_index()\n",
    "    df = df.set_axis(['Code','gene','finngen_eqtl_'+tissue+'_closest_opposite','finngen_eqtl_'+tissue+'_closest_same'],axis=1)\n",
    "    te = te.merge(df, on=['Code','gene'], how='outer')\n",
    "\n",
    "te.to_pickle('./Features/finngen_eqtl_tissue_closest.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce6fa3c-b30c-439d-89e3-963745031a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create rare variant features\n",
    "df = pd.read_csv('./Finngen/rare_missense_lof.tsv', sep='\\t')\n",
    "vep = pd.read_pickle('./Finngen/Annotations/vep_cleaned.pkl')\n",
    "vep = vep[['ID','SYMBOL','annotation']].set_axis(['id','gene','annotation'],axis=1).dropna()\n",
    "df = df.merge(vep).merge(fg)\n",
    "df = df[['id','beta','log10p','gene','annotation','Code']]\n",
    "df = df.sort_values('log10p', ascending=False).drop_duplicates(['Code','gene','annotation'])\n",
    "df.loc[df['beta'] < 0, 'log10p'] = df['log10p']*-1\n",
    "df = pd.pivot_table(df, index=['Code','gene'], columns='annotation', values='log10p').reset_index()\n",
    "df = df.set_axis(['Code','gene','finngen_sv_hclof','finngen_sv_lclof','finngen_sv_gof',\n",
    "                  'finngen_sv_other_0.5missense','finngen_sv_other_missense'],axis=1)\n",
    "df.to_pickle('./Features/finngen_sv.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5f4a464-9e22-439b-a1b6-7f49b797e136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create gene burden features\n",
    "fl = pd.read_csv('./Finngen/LOF/finngen_R12_lof.txt', sep='\\t')\n",
    "fl = fl.drop(['CHROM','GENPOS','ALLELE0','SE','CHISQ','EXTRA'],axis=1)\n",
    "fl['MAC'] = fl['A1FREQ']*fl['N']*2\n",
    "fl = fl.loc[fl['LOG10P'] >= -np.log10(0.05)]\n",
    "fl = fl.loc[fl['MAC'] >= 10]\n",
    "fl['gene'] = fl['ID'].str.split('.').str[0]\n",
    "fl = fl.rename({'PHENO':'pheno'},axis=1).merge(fg)\n",
    "fl = fl.sort_values('LOG10P',ascending=False).drop_duplicates(['Code','gene'])\n",
    "fl.loc[fl['BETA'] < 0, 'LOG10P'] = fl['LOG10P']*-1\n",
    "fl = fl[['Code','gene','LOG10P']].rename({'LOG10P':'finngen_gb_lof'},axis=1)\n",
    "fl.to_pickle('./Features/finngen_gb.pkl')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
