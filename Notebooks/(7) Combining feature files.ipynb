{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d07f563-5292-4115-9a01-4fd36cc483f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "###\n",
    "\n",
    "targets = pd.read_pickle('./OT/Final/targets.pkl')\n",
    "\n",
    "# See \"Diseases.ipynb\" for these files\n",
    "custom = pd.read_excel('./Phenotyping/custom_phenotypes.xlsx')\n",
    "custom['phecode1.2'] = custom['phecode1.2'].astype(float)\n",
    "icd = pd.read_csv('./Phenotyping/icd_codes.csv')\n",
    "merged_pheno = pd.read_excel('./Phenotyping/merged_phenotypes.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7a96cb-c0cb-48b2-89d3-92bb0fa700c3",
   "metadata": {},
   "source": [
    "## Phenotype-agnostic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc644ec5-ab25-4410-acfd-dc9dc4927fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Druggable genes only\n",
    "genes = pd.read_pickle('./OT/Final/protein_coding_genes.pkl')\n",
    "genes = genes.loc[~genes['gene'].str.contains('ENSG')]\n",
    "tg = pd.read_pickle('./Drugs/targets.pkl')[['gene','moa']]\n",
    "tg = tg.loc[tg['gene'].isin(genes['gene'])]\n",
    "tg['value'] = 1\n",
    "tg = pd.pivot_table(tg, index='gene', columns='moa', values='value').fillna(0).reset_index()\n",
    "tg = tg.set_axis(['gene','neg','other','pos'],axis=1)\n",
    "\n",
    "tp = pd.read_pickle('./Features/tp.pkl').drop('tdl',axis=1)\n",
    "constraint = pd.read_pickle('./Features/constraint.pkl')\n",
    "ess = pd.read_pickle('./Features/ess_haplo.pkl')\n",
    "tg = tg.merge(tp, on='gene', how='left').merge(constraint, on='gene', how='left').merge(ess, on='gene', how='left')\n",
    "tg = tg.drop_duplicates('gene')\n",
    "tg.to_pickle('./OT/Final/gene_direction.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d3c0f3-ae78-4398-b3ef-62193b1f3e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All genes\n",
    "genes = pd.read_pickle('./OT/Final/protein_coding_genes.pkl')\n",
    "genes = genes.loc[~genes['gene'].str.contains('ENSG')]\n",
    "genes = genes.merge(pd.read_pickle('./Drugs/drug_genes.pkl'), how='left')\n",
    "genes = genes.merge(pd.read_csv('./Other/pharos.csv')[['Symbol','Target Development Level']].set_axis(['gene','tdl'],axis=1), how='left')\n",
    "genes = genes.drop_duplicates('gene')\n",
    "genes['tdl'] = genes['tdl'].fillna('Tdark')\n",
    "\n",
    "genes['tclin_tchem'] = 0\n",
    "genes.loc[genes['tdl'].isin(['Tchem','Tclin']), 'tclin_tchem'] = 1\n",
    "genes['druggable'] = 0\n",
    "genes.loc[(genes['source'].notna()) | (genes['tdl'].isin(['Tchem','Tclin'])), 'druggable'] = 1\n",
    "\n",
    "tg = pd.read_pickle('./Drugs/targets.pkl')[['gene','moa']]\n",
    "tg['value'] = 1\n",
    "tg = pd.pivot_table(tg, index='gene', columns='moa', values='value').fillna(0).reset_index()\n",
    "tg = tg.set_axis(['gene','neg','other','pos'],axis=1)\n",
    "genes = genes.merge(tg, how='left')\n",
    "genes[['neg','pos','other']] = genes[['neg','pos','other']].fillna(0)\n",
    "\n",
    "tp = pd.read_pickle('./Features/tp.pkl').drop('tdl',axis=1)\n",
    "constraint = pd.read_pickle('./Features/constraint.pkl')\n",
    "ess = pd.read_pickle('./Features/ess_haplo.pkl')\n",
    "genes = genes.merge(tp, on='gene', how='left').merge(constraint, on='gene', how='left').merge(ess, on='gene', how='left')\n",
    "genes = genes.drop_duplicates('gene')\n",
    "genes.to_pickle('./OT/Final/gene_direction_all.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc0da8f-52da-4f6a-8c16-288fe3d06469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset analyses\n",
    "subsets = pd.read_pickle('./OT/Final/gene_direction_all.pkl')\n",
    "subsets.loc[subsets['lof.oe_ci.upper'] >= 0.6, 'not_constrained'] = 1\n",
    "subsets.loc[subsets['lof.oe_ci.upper'] < 0.6, 'constrained'] = 1\n",
    "subsets = subsets.merge(pd.read_csv('./Other/pharos.csv')[['Symbol','Novelty']].set_axis(['gene','novelty'],axis=1))\n",
    "subsets.loc[subsets['novelty'] >= subsets['novelty'].median(), 'novel'] = 1\n",
    "print(subsets['novelty'].median())\n",
    "subsets = subsets[['gene','class_enzyme','class_transporter','class_tf','class_gpcr','class_vgic','constrained','not_constrained','novel']]\n",
    "subsets.to_pickle('./OT/Final/subsets.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0fc36fe-b8c6-4434-b02d-ed93855269d3",
   "metadata": {},
   "source": [
    "## Phenotype-specific"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72fde902-1310-4d06-ae0e-d1e821d9fe08",
   "metadata": {},
   "source": [
    "### Only druggable genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7d346b-a266-40fa-8e59-be998126cb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all dataframes\n",
    "df0 = pd.read_pickle('./Drugs/combined.pkl')[['Code','gene']]\n",
    "df1 = pd.read_pickle('./Features/finngen_eqtl.pkl')\n",
    "df2 = pd.read_pickle('./Features/l2g.pkl')\n",
    "df3 = pd.read_pickle('./Features/mvp_eqtl.pkl')\n",
    "df4 = pd.read_pickle('./Features/panukbb_eqtl.pkl')\n",
    "df5 = pd.read_pickle('./Features/finngen_sv.pkl')\n",
    "df6 = pd.read_pickle('./Features/genebass_sv.pkl')\n",
    "df8 = pd.read_pickle('./Features/finngen_gb.pkl')\n",
    "df9 = pd.read_pickle('./Features/genebass_gb.pkl')\n",
    "df10 = pd.read_pickle('./Features/jurgens.pkl')\n",
    "df11 = pd.read_pickle('./Features/ot_gb.pkl')\n",
    "df12 = pd.read_pickle('./Features/eva.pkl')\n",
    "df13 = pd.read_pickle('./Features/orphanet_g2p.pkl')\n",
    "df14 = pd.read_pickle('./Features/impc.pkl')\n",
    "df15 = pd.read_pickle('./Features/finngen_eqtl_closest.pkl')\n",
    "df16 = pd.read_pickle('./Features/mvp_eqtl_closest.pkl')\n",
    "df17 = pd.read_pickle('./Features/panukbb_eqtl_closest.pkl')\n",
    "\n",
    "dfs = [df0, df1, df2, df3, df4, \n",
    "       df5, df6, df8, df9, df10,\n",
    "       df11, df12, df13, df14,\n",
    "       df15, df16, df17]\n",
    "result = dfs[0]\n",
    "for df in dfs[1:]:\n",
    "    result = result.merge(df, on=[\"Code\", \"gene\"], how=\"left\")\n",
    "\n",
    "result = result.replace({np.inf: 325, -np.inf: -325})\n",
    "result.to_pickle('./Training/input.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ea57ed-6d88-4419-9372-d857df46de19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only screened phenotypes\n",
    "keep = pd.read_excel('./Phenotyping/nonspecific_codes.xlsx')\n",
    "keep = keep.loc[keep['Include'] == 'y']\n",
    "keep['Nonspecific'] = keep['Nonspecific'].fillna(0)\n",
    "db = pd.read_excel('./Phenotyping/present_pheno.xlsx')\n",
    "input = pd.read_pickle('./Training/input.pkl')\n",
    "input = input.merge(db).merge(keep[['Code','Category','Nonspecific']].drop_duplicates())\n",
    "input['Category'] = pd.Categorical(input['Category'])\n",
    "\n",
    "# Where pheno present and value missing, fill with 0\n",
    "for col in ['eva_hclof', 'eva_lclof', 'eva_gof', 'impc_lof', 'l2g_activator', 'l2g_inhibitor', \n",
    "            'ot_gene_burden', 'orphanet_g2p_lof', 'eva_other_missense']:\n",
    "    input.loc[(input['OT'] == 1) & (input[col].isna()), col] = 0\n",
    "input.loc[input['MVP'] == 1, input.columns.str.contains('mvp_')] = input.loc[input['MVP'] == 1, input.columns.str.contains('mvp_')].fillna(0)\n",
    "input.loc[input['FinnGen'] == 1, input.columns.str.contains('finngen_')] = input.loc[input['FinnGen'] == 1, input.columns.str.contains('finngen_')].fillna(0)\n",
    "input.loc[input['Jurgens'] == 1, input.columns.str.contains('jurgens_')] = input.loc[input['Jurgens'] == 1, input.columns.str.contains('jurgens_')].fillna(0)\n",
    "input.loc[input['PanUKBB'] == 1, input.columns.str.contains('panukbb_')] = input.loc[input['PanUKBB'] == 1, input.columns.str.contains('panukbb_')].fillna(0)\n",
    "input.loc[input['Genebass'] == 1, input.columns.str.contains('genebass_')] = input.loc[input['Genebass'] == 1, input.columns.str.contains('genebass_')].fillna(0)\n",
    "input = input.drop(['OT','Jurgens','MVP','PanUKBB','Genebass','FinnGen'],axis=1)\n",
    "\n",
    "input['locus2gene'] = input['l2g_activator'].copy()\n",
    "input.loc[input['l2g_inhibitor'] > input['l2g_activator'], 'locus2gene'] = -1*input['l2g_inhibitor']\n",
    "input['panukbb_eqtl'] = input['panukbb_eqtl_closest_opposite'].copy()\n",
    "input.loc[input['panukbb_eqtl_closest_same'] > input['panukbb_eqtl_closest_opposite'], 'panukbb_eqtl'] = -1*input['panukbb_eqtl_closest_same']\n",
    "input['finngen_eqtl'] = input['finngen_eqtl_closest_opposite'].copy()\n",
    "input.loc[input['finngen_eqtl_closest_same'] > input['finngen_eqtl_closest_opposite'], 'finngen_eqtl'] = -1*input['finngen_eqtl_closest_same']\n",
    "input['mvp_eqtl'] = input['mvp_eqtl_closest_opposite'].copy()\n",
    "input.loc[input['mvp_eqtl_closest_same'] > input['mvp_eqtl_closest_opposite'], 'mvp_eqtl'] = -1*input['mvp_eqtl_closest_same']\n",
    "\n",
    "constraint = pd.read_pickle('./Features/constraint.pkl')[['gene','lof.oe_ci.upper_bin_decile']]\n",
    "input = input.merge(constraint, on='gene', how='left')\n",
    "\n",
    "ns = pd.read_excel('./Phenotyping/nonspecific_codes.xlsx')[['Code','Nonspecific']].fillna(0)\n",
    "input = input.merge(ns)\n",
    "input = input.drop_duplicates(['Code','gene'])\n",
    "input.to_pickle('./Training/input_extended.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e1df3a-8db5-429d-b375-9e663863c4a5",
   "metadata": {},
   "source": [
    "### All supported genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b621db13-ccfe-4732-b203-5d3fa64e8cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "keep = pd.read_excel('./Phenotyping/nonspecific_codes.xlsx')\n",
    "keep = keep.loc[keep['Include'] == 'y']\n",
    "genes = pd.read_pickle('./OT/Final/protein_coding_genes.pkl')\n",
    "genes = genes.loc[~genes['gene'].str.contains('ENSG')]\n",
    "\n",
    "combinations = list(itertools.product(keep['Code'], genes['gene']))\n",
    "df0 = pd.DataFrame(combinations, columns=['Code', 'gene'])\n",
    "\n",
    "df1 = pd.read_pickle('./Features/finngen_eqtl.pkl')\n",
    "df2 = pd.read_pickle('./Features/l2g.pkl')\n",
    "df3 = pd.read_pickle('./Features/mvp_eqtl.pkl')\n",
    "df4 = pd.read_pickle('./Features/panukbb_eqtl.pkl')\n",
    "df5 = pd.read_pickle('./Features/finngen_sv.pkl')\n",
    "df6 = pd.read_pickle('./Features/genebass_sv.pkl')\n",
    "df8 = pd.read_pickle('./Features/finngen_gb.pkl')\n",
    "df9 = pd.read_pickle('./Features/genebass_gb.pkl')\n",
    "df10 = pd.read_pickle('./Features/jurgens.pkl')\n",
    "df11 = pd.read_pickle('./Features/ot_gb.pkl')\n",
    "df12 = pd.read_pickle('./Features/eva.pkl')\n",
    "df13 = pd.read_pickle('./Features/orphanet_g2p.pkl')\n",
    "df14 = pd.read_pickle('./Features/impc.pkl')\n",
    "df15 = pd.read_pickle('./Features/finngen_eqtl_closest.pkl')\n",
    "df16 = pd.read_pickle('./Features/mvp_eqtl_closest.pkl')\n",
    "df17 = pd.read_pickle('./Features/panukbb_eqtl_closest.pkl')\n",
    "\n",
    "dfs = [df0, df1, df2, df3, df4,\n",
    "       df5, df6, df8, df9, df10,\n",
    "       df11, df12, df13, df14,\n",
    "       df15, df16, df17]\n",
    "result = dfs[0]\n",
    "for df in dfs[1:]:\n",
    "    result = result.merge(df, on=[\"Code\", \"gene\"], how=\"left\")\n",
    "\n",
    "result = result.replace({np.inf: 325, -np.inf: -325})\n",
    "result.to_pickle('./Training/input_all.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2d2730-33ac-4f91-8cdc-a11be65d93a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only screened phenotypes\n",
    "keep = pd.read_excel('./Phenotyping/nonspecific_codes.xlsx')\n",
    "keep = keep.loc[keep['Include'] == 'y']\n",
    "keep['Nonspecific'] = keep['Nonspecific'].fillna(0)\n",
    "db = pd.read_excel('./Phenotyping/present_pheno.xlsx')\n",
    "input = pd.read_pickle('./Training/input_all.pkl')\n",
    "input = input.merge(db).merge(keep[['Code','Category','Nonspecific']].drop_duplicates())\n",
    "input['Category'] = pd.Categorical(input['Category'])\n",
    "\n",
    "# Where pheno present and value missing, fill with 0\n",
    "for col in ['eva_hclof', 'eva_lclof', 'eva_gof', 'impc_lof', 'l2g_activator', 'l2g_inhibitor', \n",
    "            'ot_gene_burden', 'orphanet_g2p_lof', 'eva_other_missense']:\n",
    "    input.loc[(input['OT'] == 1) & (input[col].isna()), col] = 0\n",
    "input.loc[input['MVP'] == 1, input.columns.str.contains('mvp_')] = input.loc[input['MVP'] == 1, input.columns.str.contains('mvp_')].fillna(0)\n",
    "input.loc[input['FinnGen'] == 1, input.columns.str.contains('finngen_')] = input.loc[input['FinnGen'] == 1, input.columns.str.contains('finngen_')].fillna(0)\n",
    "input.loc[input['Jurgens'] == 1, input.columns.str.contains('jurgens_')] = input.loc[input['Jurgens'] == 1, input.columns.str.contains('jurgens_')].fillna(0)\n",
    "input.loc[input['PanUKBB'] == 1, input.columns.str.contains('panukbb_')] = input.loc[input['PanUKBB'] == 1, input.columns.str.contains('panukbb_')].fillna(0)\n",
    "input.loc[input['Genebass'] == 1, input.columns.str.contains('genebass_')] = input.loc[input['Genebass'] == 1, input.columns.str.contains('genebass_')].fillna(0)\n",
    "input = input.drop(['OT','Jurgens','MVP','PanUKBB','Genebass','FinnGen'],axis=1)\n",
    "\n",
    "input['locus2gene'] = input['l2g_activator'].copy()\n",
    "input.loc[input['l2g_inhibitor'] > input['l2g_activator'], 'locus2gene'] = -1*input['l2g_inhibitor']\n",
    "input['panukbb_eqtl'] = input['panukbb_eqtl_closest_opposite'].copy()\n",
    "input.loc[input['panukbb_eqtl_closest_same'] > input['panukbb_eqtl_closest_opposite'], 'panukbb_eqtl'] = -1*input['panukbb_eqtl_closest_same']\n",
    "input['finngen_eqtl'] = input['finngen_eqtl_closest_opposite'].copy()\n",
    "input.loc[input['finngen_eqtl_closest_same'] > input['finngen_eqtl_closest_opposite'], 'finngen_eqtl'] = -1*input['finngen_eqtl_closest_same']\n",
    "input['mvp_eqtl'] = input['mvp_eqtl_closest_opposite'].copy()\n",
    "input.loc[input['mvp_eqtl_closest_same'] > input['mvp_eqtl_closest_opposite'], 'mvp_eqtl'] = -1*input['mvp_eqtl_closest_same']\n",
    "\n",
    "constraint = pd.read_pickle('./Features/constraint.pkl')[['gene','lof.oe_ci.upper_bin_decile']]\n",
    "input = input.merge(constraint, on='gene', how='left')\n",
    "\n",
    "ns = pd.read_excel('./Phenotyping/nonspecific_codes.xlsx')[['Code','Nonspecific']].fillna(0)\n",
    "input = input.merge(ns)\n",
    "input = input.drop_duplicates(['Code','gene'])\n",
    "\n",
    "raresv = ['genebass_sv_hclof', 'genebass_sv_lclof', 'genebass_sv_lof_0.5missense','genebass_sv_lof_missense',\n",
    "          'genebass_sv_gof_0.5missense', 'genebass_sv_gof_missense', 'genebass_sv_hcgof',\n",
    "          'finngen_sv_hclof', 'finngen_sv_lclof','finngen_sv_gof',\n",
    "          'genebass_sv_other_0.5missense', 'genebass_sv_other_missense', 'finngen_sv_other_0.5missense', 'finngen_sv_other_missense']\n",
    "eqtl = ['l2g_activator', 'l2g_inhibitor',\n",
    "         'panukbb_eqtl', 'finngen_eqtl', 'mvp_eqtl']\n",
    "gb = ['genebass_gb_hclof_missense', 'genebass_gb_hclof','genebass_gb_hclof_lclof_missense',\n",
    "      'jurgens_lof', 'jurgens_lof_0.5missense', 'jurgens_lof_0.8missense','jurgens_0.2missense', 'jurgens_0.5missense',\n",
    "      'finngen_gb_lof']\n",
    "otp_unique = ['eva_hclof', 'eva_lclof', 'eva_gof', 'impc_lof']\n",
    "target = ['lof.oe_ci.upper_bin_decile','Category', 'Nonspecific']\n",
    "\n",
    "input['sources'] = (input[eqtl+raresv+gb+otp_unique].abs() > 0.001).sum(axis=1)\n",
    "input.to_pickle('./Training/input_extended_all.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e3611c-39f5-4eb7-bb62-809a560dd345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only rows with Mantis-ML or OT support\n",
    "mantis = pd.read_pickle('./Other/mantis_cleaned.pkl')\n",
    "mantis['ID'] = mantis['Code'] + '|' + mantis['Gene']\n",
    "mantis = mantis[['ID','Mantis']].drop_duplicates()\n",
    "da = pd.read_pickle('./OT/Final/direct_associations.pkl')\n",
    "da['ID'] = da['Code'] + '|' + da['gene']\n",
    "da = da[['ID','score']].drop_duplicates().rename({'score':'OT'},axis=1)\n",
    "evidence = mantis.loc[mantis['Mantis'] > 0.5]['ID'].to_list() + da.loc[da['OT'] > 0.1]['ID'].to_list()\n",
    "\n",
    "input['ID'] = input['Code'] + '|' + input['gene']\n",
    "input = input.loc[(input['ID'].isin(evidence)) & (input['sources'] > 0)]\n",
    "input.to_pickle('./Training/input_extended_all_filtered.pkl')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
