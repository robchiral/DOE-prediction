{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ecc44e68-5707-4d83-90b3-6ccad87e8e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "import numpy as np\n",
    "\n",
    "def normalized_harmonic_sum(x):\n",
    "    x_sorted = np.sort(x)[::-1]\n",
    "    harmonic_sum = np.sum(x_sorted / (np.arange(1, len(x_sorted) + 1) ** 2))\n",
    "    max_harmonic_sum = 1.644  # Given approximation for a vector of 1,000 ones\n",
    "    return harmonic_sum / max_harmonic_sum\n",
    "    \n",
    "###\n",
    "\n",
    "map = pd.read_pickle('./OT/Final/diseases.pkl')\n",
    "map['code'] = map['code'].astype(str)\n",
    "\n",
    "direct_map = map.loc[map['Code'].notna()][['id','Code']]\n",
    "\n",
    "mondo_map = map.loc[map['terminology'] == 'MONDO'][['code','id']]\n",
    "mondo_map = mondo_map.merge(direct_map)\n",
    "mondo_map['id'] = 'MONDO_' + mondo_map['code'].astype(str)\n",
    "mondo_map = mondo_map[['id','Code']]\n",
    "\n",
    "hp_map = map.loc[map['terminology'] == 'HP'][['code','id']]\n",
    "hp_map = hp_map.merge(direct_map)\n",
    "hp_map['id'] = 'HP_' + hp_map['code'].astype(str)\n",
    "hp_map = hp_map[['id','Code']]\n",
    "\n",
    "orpha_map = map.loc[map['terminology'] == 'Orphanet'][['code','id']]\n",
    "orpha_map = orpha_map.merge(direct_map)\n",
    "orpha_map['id'] = 'Orphanet_' + orpha_map['code'].astype(str)\n",
    "orpha_map = orpha_map[['id','Code']]\n",
    "\n",
    "efo_map = map.loc[map['terminology'] == 'EFO'][['code','id']]\n",
    "efo_map = efo_map.merge(direct_map)\n",
    "efo_map['id'] = 'EFO_' + efo_map['code'].astype(str)\n",
    "efo_map = efo_map[['id','Code']]\n",
    "\n",
    "eva_map = pd.concat([direct_map, mondo_map, hp_map, orpha_map, efo_map]).drop_duplicates(['id','Code'])\n",
    "eva_map = eva_map.rename({'id':'disease'},axis=1)\n",
    "\n",
    "d = eva_map[['Code']].drop_duplicates()\n",
    "d['OT'] = 1\n",
    "d.to_csv('./Phenotyping/ot_present.csv', index=False)\n",
    "\n",
    "###\n",
    "\n",
    "targets = pd.read_pickle('./OT/Final/targets.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706ea685-20ab-4eac-9256-ee522de36f0d",
   "metadata": {},
   "source": [
    "## Locus2gene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b2297363-9392-4edf-b8c3-7c73d904a8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "l2g = pd.read_pickle('./OT/Raw/ot_genetics_portal.pkl').rename({'diseaseId':'disease','targetId':'gene_id'},axis=1)\n",
    "l2g = l2g.merge(eva_map).merge(targets)\n",
    "l2g = l2g[['Code','gene','projectId','studyId','variantId','score','variantEffect','directionOnTrait']]\n",
    "l2g = l2g.loc[l2g['variantEffect'].notna() & l2g['directionOnTrait'].notna()]\n",
    "l2g = l2g.sort_values('score',ascending=False).drop_duplicates(['Code','gene','variantId','variantEffect','directionOnTrait'])\n",
    "l2g.loc[(l2g['variantEffect'] == 'GoF') & (l2g['directionOnTrait'] == 'risk'), 'moa'] = 'inhibitor'\n",
    "l2g.loc[(l2g['variantEffect'] == 'GoF') & (l2g['directionOnTrait'] == 'protect'), 'moa'] = 'activator'\n",
    "l2g.loc[(l2g['variantEffect'] == 'LoF') & (l2g['directionOnTrait'] == 'risk'), 'moa'] = 'activator'\n",
    "l2g.loc[(l2g['variantEffect'] == 'LoF') & (l2g['directionOnTrait'] == 'protect'), 'moa'] = 'inhibitor'\n",
    "l2g = pd.pivot_table(l2g, index=['Code','gene'], columns='moa', values='score', aggfunc=normalized_harmonic_sum).reset_index()\n",
    "l2g = l2g.set_axis(['Code','gene','l2g_activator','l2g_inhibitor'],axis=1)\n",
    "l2g.to_pickle('./Features/l2g.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbafa739-5a23-4862-8dea-a969ab968eaf",
   "metadata": {},
   "source": [
    "## Gene burden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4861424c-35d1-4000-af29-1540b399b2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = pd.read_pickle('./OT/Raw/gene_burden.pkl').rename({'diseaseId':'disease','targetId':'gene_id'},axis=1)\n",
    "gb = gb.merge(eva_map).merge(targets)\n",
    "gb = gb[['Code','gene','score','directionOnTrait','cohortId']]\n",
    "gb.loc[gb['cohortId'].str.contains('UK Biobank', na=False), 'cohortId'] = 'UK Biobank'\n",
    "gb = gb.sort_values('score',ascending=False).drop_duplicates(['Code','gene','cohortId','directionOnTrait'])\n",
    "gb = pd.pivot_table(gb, index=['Code','gene'], columns='directionOnTrait', values='score', aggfunc=normalized_harmonic_sum).reset_index()\n",
    "gb['ot_gene_burden'] = gb['protect']*-1\n",
    "gb.loc[(gb['risk'] >= gb['protect']) | (gb['protect'].isna()), 'ot_gene_burden'] = gb['risk']\n",
    "gb = gb[['Code','gene','ot_gene_burden']]\n",
    "gb.to_pickle('./Features/ot_gb.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a4638b-0409-4c79-940d-41f4e9086169",
   "metadata": {},
   "source": [
    "## IMPC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a08e383a-c967-4cf4-a977-a45ef41c1da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "impc = pd.read_pickle('./OT/Raw/impc.pkl').rename({'diseaseId':'disease','targetId':'gene_id'},axis=1)\n",
    "impc = impc.merge(eva_map).merge(targets)\n",
    "impc = impc[['biologicalModelId','biologicalModelAllelicComposition','biologicalModelGeneticBackground',\n",
    "             'Code','gene','score']].drop_duplicates()\n",
    "impc['datasourceId'] = 'impc_lof'\n",
    "impc = pd.pivot_table(impc, index=['Code','gene'], columns='datasourceId', values='score', aggfunc=normalized_harmonic_sum).reset_index()\n",
    "impc.to_pickle('./Features/impc.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1f6915-0420-4578-abf3-d58ec124e161",
   "metadata": {},
   "source": [
    "## Orphanet and Gene2phenotype (combining due to sparsity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba709aef-5818-488f-a53d-36fb6b1e27c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "orpha = pd.read_pickle('./OT/Raw/orphanet.pkl').rename({'diseaseId':'disease','targetId':'gene_id'},axis=1)\n",
    "orpha = orpha.merge(eva_map).merge(targets)\n",
    "orpha = orpha[['Code','gene','variantEffect','score']].dropna()\n",
    "orpha['value'] = 1\n",
    "orpha = pd.pivot_table(orpha, index=['Code','gene'], columns='variantEffect', values='value', aggfunc='max').reset_index()\n",
    "orpha = orpha.set_axis(['Code','gene','gof','lof'],axis=1)\n",
    "\n",
    "g2p = pd.read_pickle('./OT/Raw/gene2phenotype.pkl').rename({'diseaseId':'disease','targetId':'gene_id'},axis=1)\n",
    "g2p = g2p.merge(eva_map).merge(targets)\n",
    "g2p = g2p.loc[g2p['score'] >= 0.5] # remove limited evidence\n",
    "g2p = g2p[['Code','gene','variantEffect']].dropna()\n",
    "g2p['value'] = 1\n",
    "g2p = pd.pivot_table(g2p, index=['Code','gene'], columns='variantEffect', values='value', aggfunc='max').reset_index()\n",
    "g2p = g2p.set_axis(['Code','gene','gof','lof'],axis=1)\n",
    "\n",
    "go = pd.concat([orpha,g2p])\n",
    "go = go.set_axis(['Code','gene','orphanet_g2p_gof','orphanet_g2p_lof'],axis=1)\n",
    "go.to_pickle('./Features/orphanet_g2p.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ced563-87c4-4b22-86a6-27d46d64d7f7",
   "metadata": {},
   "source": [
    "## ClinVar and UniProt variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "65b27766-d1bd-48ba-806a-a7cc082cfa5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "eva = pd.read_pickle('./OT/Raw/eva.pkl').rename({'diseaseId':'disease','targetId':'gene_id'},axis=1)\n",
    "eva = eva.merge(eva_map).merge(targets)\n",
    "eva = eva[['Code','gene','variantId','score','clinicalSignificances','confidence','variantEffect','directionOnTrait']]\n",
    "eva = eva.sort_values('score', ascending=False).drop_duplicates(['Code','variantId'])\n",
    "\n",
    "es = pd.read_pickle('./OT/Raw/eva_somatic.pkl').rename({'diseaseId':'disease','targetId':'gene_id'},axis=1)\n",
    "es = es.merge(eva_map).merge(targets)\n",
    "es = es[['Code','gene','variantId','score','clinicalSignificances','confidence','variantEffect','directionOnTrait']]\n",
    "es = es.sort_values('score', ascending=False).drop_duplicates(['Code','variantId'])\n",
    "\n",
    "eva = pd.concat([eva,es])\n",
    "eva.to_pickle('./OT/Processing/eva_cleaned.pkl')\n",
    "\n",
    "up = pd.read_pickle('./OT/Raw/uniprot_variants.pkl').rename({'diseaseId':'disease','targetId':'gene_id'},axis=1)\n",
    "up = up.merge(eva_map).merge(targets)\n",
    "up = up[['Code','gene','variantId','score']]\n",
    "up = up.sort_values('score', ascending=False).drop_duplicates(['Code','variantId'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8fe8be4c-7b30-488e-977d-df4ab01c135e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write ClinVar variants to VCF for VEP\n",
    "evep = pd.concat([eva[['variantId']].drop_duplicates(),es[['variantId']].drop_duplicates(),up[['variantId']].drop_duplicates()])\n",
    "evep = evep.drop_duplicates().dropna()\n",
    "\n",
    "evep['chr'] = evep['variantId'].str.split('_').str[0].astype(object)\n",
    "evep['pos'] = evep['variantId'].str.split('_').str[1].astype(int)\n",
    "evep['ref'] = evep['variantId'].str.split('_').str[2]\n",
    "evep['alt'] = evep['variantId'].str.split('_').str[3]\n",
    "evep['qual'] = '.'\n",
    "evep['filter'] = '.'\n",
    "evep['info'] = '.'\n",
    "evep['id'] = evep['variantId'].copy()\n",
    "\n",
    "vcf_columns = ['chr', 'pos', 'id', 'ref', 'alt', 'qual', 'filter', 'info']\n",
    "vcf_df = evep[vcf_columns]\n",
    "vcf_df = vcf_df.sort_values(['chr','pos','ref','alt'])\n",
    "\n",
    "vcf_header = \"\"\"##fileformat=VCFv4.2\n",
    "##source=CustomGeneratedVCF\n",
    "#CHROM\\tPOS\\tID\\tREF\\tALT\\tQUAL\\tFILTER\\tINFO\n",
    "\"\"\"\n",
    "with open('./OT/Processing/eva_unique.vcf', 'w') as f:\n",
    "    f.write(vcf_header)\n",
    "    vcf_df.to_csv(f, sep='\\t', index=False, header=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "id": "c5ebe611-f1da-4d4a-807a-de024fdeb793",
   "metadata": {},
   "source": [
    "# Run VEP\n",
    "ml CPAN\n",
    "ml tabix\n",
    "ml vep/112\n",
    "ml perl/5.40.0\n",
    "ml samtools\n",
    "ml htslib\n",
    "\n",
    "bsub -q premium -P acc_GENECAD -W 39:59 -n 12 -o run.out -e run.error -R span[hosts=1] -R rusage[mem=3GB] \"vep -i /sc/arion/projects/GENECAD/Robert/DOE/OT/Processing/eva_unique.vcf --fork 6 --cache --dir_cache /hpc/packages/minerva-centos7/vep/112/cache/ --offline --assembly GRCh38 --dir_plugins /sc/arion/projects/GENECAD/Robert/Software/loftee-1.0.4/ --output_file /sc/arion/projects/GENECAD/Robert/DOE/OT/Processing/eva_unique_loftee.vcf --no_stats --force_overwrite --vcf --symbol --canonical --mane_select --show_ref_allele --plugin LoF,loftee_path:/sc/arion/projects/GENECAD/Robert/Software/loftee-1.0.4/,human_ancestor_fa:/sc/arion/projects/GENECAD/Robert/Software/human_ancestor/human_ancestor.fa.gz,conservation_file:/sc/arion/projects/GENECAD/Robert/Software/conservation_file/loftee.sql\"\n",
    "\n",
    "bsub -q premium -P acc_GENECAD -W 39:59 -n 4 -o run.out -e run.error -R span[hosts=1] -R rusage[mem=3GB] filter_vep -i /sc/arion/projects/GENECAD/Robert/DOE/OT/Processing/eva_unique_loftee.vcf -o /sc/arion/projects/GENECAD/Robert/DOE/OT/Processing/eva_unique_loftee_filter.vcf --format vcf --force_overwrite --filter \"(CANONICAL is YES)\" --only_matched\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "91aaeaf1-be7c-42da-a2ce-61d71458f437",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1957155/343295352.py:1: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  vcf = pd.read_csv('./OT/Processing/eva_unique_loftee_filter.vcf', sep='\\t', skiprows=53)\n",
      "/tmp/ipykernel_1957155/343295352.py:25: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  lof = pd.read_csv('./LoGoFunc/filtered_LOGO_LOF.csv', sep='\\t')\n"
     ]
    }
   ],
   "source": [
    "vcf = pd.read_csv('./OT/Processing/eva_unique_loftee_filter.vcf', sep='\\t', skiprows=53)\n",
    "vcf = vcf.set_axis(['CHROM','POS','ID','REF','ALT','QUAL','FILTER','INFO'],axis=1).drop(['QUAL','FILTER'],axis=1)\n",
    "vcf = vcf.assign(INFO=vcf['INFO'].str.split(',')).explode('INFO')\n",
    "vcf['INFO'] = vcf['INFO'].str.split('|')\n",
    "\n",
    "column_names = [\n",
    "    'Allele', 'Consequence', 'IMPACT', 'SYMBOL', 'Gene', 'Feature_type', 'Feature',\n",
    "    'BIOTYPE', 'EXON', 'INTRON', 'HGVSc', 'HGVSp', 'cDNA_position', 'CDS_position',\n",
    "    'Protein_position', 'Amino_acids', 'Codons', 'Existing_variation', 'REF_ALLELE',\n",
    "    'DISTANCE', 'STRAND', 'FLAGS', 'SYMBOL_SOURCE', 'HGNC_ID', 'CANONICAL', 'MANE_SELECT',\n",
    "    'LoF','LoF_filter','LoF_flags','LoF_info'\n",
    "]\n",
    "\n",
    "vcf[column_names] = pd.DataFrame(vcf['INFO'].tolist(), index=vcf.index)\n",
    "vcf = vcf.drop(columns=['INFO'])\n",
    "vcf.loc[vcf['Consequence'].str.contains('stop_lost|start_lost|transcript_amplification|inframe_insertion|inframe_deletion|missense_variant|protein_altering_variant',na=False),'snp_type'] = 'Missense'\n",
    "vcf.loc[vcf['Consequence'].str.contains('transcript_ablation|splice_acceptor_variant|splice_donor_variant|stop_gained|frameshift_variant',na=False),'snp_type'] = 'PTV'\n",
    "vcf = vcf.loc[vcf['IMPACT'] != 'MODIFIER']\n",
    "vcf = vcf[['ID','Consequence','SYMBOL','LoF','snp_type']]\n",
    "\n",
    "gof = pd.read_pickle('./LoGoFunc/all_predictions.pkl')\n",
    "gof = gof[['ID','LoGoFunc_GOF']]\n",
    "vcf = vcf.merge(gof, how='left')\n",
    "\n",
    "lof = pd.read_csv('./LoGoFunc/filtered_LOGO_LOF.csv', sep='\\t')\n",
    "lof = lof[['ID','LoGoFunc_LOF']]\n",
    "vcf = vcf.merge(lof, how='left')\n",
    "\n",
    "vcf['annotation'] = '5_all_other'\n",
    "vcf.loc[vcf['snp_type'] == 'Missense', 'annotation'] = '4_other_missense'\n",
    "vcf.loc[vcf['LoGoFunc_GOF'].notna(), 'annotation'] = '3_gof'\n",
    "#vcf.loc[vcf['LoGoFunc_GOF'] >= 2/3, 'annotation'] = '4_gof_mc'\n",
    "vcf.loc[vcf['LoGoFunc_LOF'].notna(), 'annotation'] = '2_lof_lc'\n",
    "#vcf.loc[vcf['LoGoFunc_LOF'] >= 2/3, 'annotation'] = '2_lof_mc'\n",
    "vcf.loc[vcf['LoF'] == 'LC', 'annotation'] = '2_lof_lc'\n",
    "vcf.loc[vcf['LoF'] == 'HC', 'annotation'] = '1_lof_hc'\n",
    "\n",
    "vcf = vcf[['ID','SYMBOL','Consequence','snp_type','annotation']]\n",
    "vcf = vcf.sort_values('annotation', ascending=True).drop_duplicates('ID')\n",
    "vcf.to_pickle('./OT/Processing/vep_annotations.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32c2d50b-0aa0-4e16-ada2-fe747ae2cb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "vcf = pd.read_pickle('./OT/Processing/vep_annotations.pkl').rename({'ID':'variantId'},axis=1)[['variantId','annotation']]\n",
    "combined = pd.read_pickle('./OT/Processing/eva_cleaned.pkl')\n",
    "combined = combined.merge(vcf, how='left')\n",
    "combined.loc[combined['annotation'].isna() & combined['variantEffect'] == 'LoF', 'annotation'] = '1_lof_hc'\n",
    "combined = combined.loc[(combined['annotation'].notna()) & (combined['directionOnTrait'] == 'risk')]\n",
    "combined = pd.pivot_table(combined, index=['Code','gene'], columns='annotation', values='score', aggfunc=normalized_harmonic_sum).reset_index()\n",
    "combined = combined.drop('5_all_other',axis=1).dropna(thresh=3, axis=1)\n",
    "combined = combined.set_axis(['Code','gene','eva_hclof','eva_lclof','eva_gof','eva_other_missense'],axis=1)\n",
    "combined.to_pickle('./Features/eva.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "c7fe3dcf-443e-4fca-ab87-f666ba94a019",
   "metadata": {},
   "outputs": [],
   "source": [
    "up = pd.read_pickle('./OT/Raw/uniprot_variants.pkl').rename({'diseaseId':'disease','targetId':'gene_id'},axis=1)\n",
    "up = up.merge(eva_map).merge(targets)\n",
    "up = up[['Code','gene','variantId','score']]\n",
    "up = up.sort_values('score', ascending=False).drop_duplicates(['Code','variantId'])\n",
    "up = up.merge(vcf)\n",
    "up = pd.pivot_table(up, index=['Code','gene'], columns='annotation', values='score', aggfunc=normalized_harmonic_sum).reset_index()\n",
    "up.to_pickle('./Features/uniprot_variants.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "e42c7050-808d-4b84-a047-768a6e3474af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Code                  96\n",
       "gene                  96\n",
       "Negative modulator    62\n",
       "Other                 31\n",
       "Positive modulator    24\n",
       "1_lof_hc              20\n",
       "2_lof_lc              61\n",
       "3_gof                 59\n",
       "4_other_missense      51\n",
       "5_all_other           23\n",
       "dtype: int64"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drugs = pd.read_pickle('./Drugs/combined.pkl')\n",
    "temp = drugs.merge(up)\n",
    "temp.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158db76d-8b61-4ce5-af5c-b243b58fa0ad",
   "metadata": {},
   "source": [
    "## Direct target-disease association scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec92453-dc9d-4ea3-9777-89cafdc02298",
   "metadata": {},
   "outputs": [],
   "source": [
    "da = pd.read_pickle('./OT/Raw/associationByOverallDirect.pkl').rename({'diseaseId':'disease','targetId':'gene_id'},axis=1)\n",
    "da = da.merge(pd.read_pickle('./OT/Final/targets.pkl')).merge(eva_map)\n",
    "da = da.groupby(['Code','gene'])['score'].max().reset_index()\n",
    "da.to_pickle('./OT/Final/direct_associations.pkl')\n",
    "\n",
    "da = pd.read_pickle('./OT/Raw/associationByOverallDirect.pkl').rename({'diseaseId':'disease','targetId':'gene_id'},axis=1)\n",
    "da = da.merge(pd.read_pickle('./OT/Final/targets.pkl'))\n",
    "da = da.groupby(['gene'])['score'].max().reset_index()\n",
    "da = da.set_axis(['gene','max_ot'],axis=1)\n",
    "da.to_pickle('./OT/Final/max_da.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6162bdd0-3794-4ce0-b988-d274a87cf07b",
   "metadata": {},
   "source": [
    "## Mantis-ML scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff180a35-3f90-4dec-920f-42f462ca5009",
   "metadata": {},
   "outputs": [],
   "source": [
    "map1 = eva_map.loc[eva_map['disease'].str.contains('HP_')]\n",
    "map1 = map1.rename({'disease':'HPO'},axis=1)\n",
    "\n",
    "# Pickled file of 2023AB_MRCONSO.RRF from UMLS\n",
    "umls = pd.read_pickle('./Other/umls.pkl')[[0,11,13]]\n",
    "umls_icd = umls.loc[umls[11].isin(['ICD10CM','ICD10PCS','ICD10'])]\n",
    "umls_icd = umls_icd[[0,13]].drop_duplicates().rename({13:'ICD10'},axis=1)\n",
    "umls_hpo = umls.loc[umls[11] == 'HPO']\n",
    "umls_hpo = umls_hpo[[0,13]].drop_duplicates().rename({13:'HPO'},axis=1)\n",
    "map2 = umls_icd.merge(umls_hpo)[['ICD10','HPO']]\n",
    "map2['HPO'] = map2['HPO'].str.replace(':','_')\n",
    "map2a = map2.merge(custom[['icd','custom_code']].dropna().drop_duplicates().set_axis(['ICD10','Code'],axis=1))\n",
    "map2a = map2a[['HPO','Code']].drop_duplicates()\n",
    "map2b = map2.copy()\n",
    "map2b['ICD10'] = map2b['ICD10'].str[:3]\n",
    "map2b = map2b.loc[map2b['ICD10'].isin(temp['Code'])]\n",
    "map2b = map2b.rename({'ICD10':'Code'},axis=1)\n",
    "\n",
    "hpo_code = pd.concat([map1,map2a,map2b]).drop_duplicates()\n",
    "\n",
    "hpo = pd.read_csv('./Other/hpo_terms.tsv', sep='\\t')\n",
    "hpo = hpo[['hpo_code','hpo_label']].set_axis(['code','disease'],axis=1)\n",
    "hpo['disease'] = hpo['disease'].str.lower()\n",
    "\n",
    "mantis = pd.read_csv('./Other/mantis_ml_scores_out-release.tsv', sep='\\t')\n",
    "mantis['disease'] = mantis['disease'].str.lower()\n",
    "mantis = mantis.merge(hpo).drop(['resource','disease'],axis=1)\n",
    "mantis = pd.melt(mantis, id_vars=['code'])\n",
    "mantis = mantis.rename({'code':'HPO'},axis=1).merge(hpo_code)\n",
    "mantis = mantis.groupby(['Code','variable'])['value'].max().reset_index()\n",
    "mantis = mantis.set_axis(['Code','Gene','Mantis'],axis=1)\n",
    "mantis.to_pickle('./Other/mantis_cleaned.pkl')\n",
    "\n",
    "mantis = pd.read_csv('./Other/mantis_ml_scores_out-release.tsv', sep='\\t').drop('resource',axis=1)\n",
    "mantis['disease'] = mantis['disease'].str.lower()\n",
    "mantis = pd.melt(mantis, id_vars=['disease'])\n",
    "mantis = mantis.groupby('variable')['value'].max().reset_index()\n",
    "mantis = mantis.set_axis(['gene','max_mantis'],axis=1)\n",
    "mantis.to_pickle('./Other/mantis_max.pkl')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
